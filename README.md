# KT

*PyTorch implementations of various Knowledge Tracing models* 

## Pre-processed Dataset

| Dataset          | Link | Train:Val:Test |
|------------------|------|----------------|
| ASSISTments2009  |      | 56:14:30       |
| ASSISTments2015  |      | 56:14:30       |
| ASSISTments2012  |      |                |
| ASSISTmentsChall |      | 6:2:2          |
| STATICS          |      | 56:14:30       |
| Junyi Academy    |      |                |
| KDDCup2010       |      |                |
| EdNet-KT1        |      |                |

## DKT (Deep Knowledge Tracing)
* Paper: https://web.stanford.edu/~cpiech/bio/papers/deepKnowledgeTracing.pdf
* Performances: 

| Dataset          | AUC  | ACC |
|------------------|------|----------------|
| ASSISTments2009  |      |        |
| ASSISTments2015  |      |        |
| ASSISTments2012  |      |                |
| ASSISTmentsChall |      |           |
| STATICS          |      |        |
| Junyi Academy    |      |                |
| KDDCup2010       |      |                |
| EdNet-KT1        |      |                |

## DKVMN (Dynamic Key-Value Memory Network) (TODO)
* Paper: http://papers.www2017.com.au.s3-website-ap-southeast-2.amazonaws.com/proceedings/p765.pdf
* Performances: 

## SAKT (Self-Attentive Knowledge Tracing) (TODO)
* Paper: https://files.eric.ed.gov/fulltext/ED599186.pdf
* Performances: 

## NPA (Neural Padagogical Agency) (TODO)
* Paper: https://arxiv.org/abs/1906.10910
* Performances: 

## SAINT (Separated self-AttentIve kNowledge Tracing) (TODO)
* Paper: https://arxiv.org/pdf/2002.07033.pdf
* Performances
